import pytest
import pandas as pd
import numpy as np
from unittest.mock import patch
from sklearn.metrics import pairwise_distances
from app.similarity_service import preprocess_data, compute_similarity, compute_similarity_matrix

@pytest.fixture
def sample_segments():
    return pd.DataFrame({
        'segment_id' : ["123-456", "123-789"],
        'grade_category': [0.0, 0.0],
        'segment_length': [10, 20],
        'start_distance': [100, 200],
        'start_time': [3600, 7200],
        'start_altitude': [300, 500],
        'elevation_gain': [100, 200],
        'avg_gradient': [0.05, 0.10],
        'road_type': ['asphalt', 'gravel'],
        'surface_type': ['smooth', 'rough'],
        'temperature': [25, 30],
        'humidity': [60, 70],
        'wind': [5, 10],
        'weather_id': [1, 2]
    })

def test_preprocess_data(sample_segments):
    # Numeric and categorical features
    numeric_features = ['segment_length', 'start_distance', 'start_time', 'start_altitude',
                        'elevation_gain', 'avg_gradient', 'temperature', 'humidity', 'wind']
    categorical_features = ['road_type', 'surface_type', 'weather_id']

    # Call the function
    X_processed, pipeline = preprocess_data(sample_segments, numeric_features, categorical_features)

    # Verify that X_processed is a numpy array
    assert isinstance(X_processed, np.ndarray)

    # Verify that the array shape corresponds to the expected shape (2 rows, 15 columns)
    assert X_processed.shape == (2, len(numeric_features) + len(sample_segments['road_type'].unique()) + len(sample_segments['surface_type'].unique()) + len(sample_segments['weather_id'].unique()))

    # Verify that the transformation of the numerical values worked
    # The value of 'segment_length' should be different after standardization
    column_transformer = pipeline.named_steps['preprocessor']
    feature_names_out = column_transformer.get_feature_names_out()
    segment_length_index = list(feature_names_out).index('num__segment_length')
    assert X_processed[0, segment_length_index] != sample_segments['segment_length'][0]

    # Get the feature names generated by the OneHotEncoder
    encoder = column_transformer.named_transformers_['cat']
    feature_names = encoder.get_feature_names_out(categorical_features)

    # Find the index for road_type_asphalt
    road_type_asphalt_index = list(feature_names_out).index('cat__road_type_asphalt')

    # Verify that categorical features have been correctly encoded
    # For road_type the corresponding column should be 1 (asphalt) or 0 (gravel)
    assert X_processed[0, road_type_asphalt_index] == 1.0  # 'asphalt' -> one-hot encoding should give 1.0
    assert X_processed[1, road_type_asphalt_index] == 0.0  # 'gravel' -> one-hot encoding should give 0.0

@pytest.fixture
def sample_grade_category_data():
    return np.array([
        [1.0, 2.0, 0.5],
        [1.5, 2.5, 0.6],
        [0.2, 0.1, 1.0],
        [0.3, 0.2, 0.9]
    ])

def test_compute_similarity(sample_grade_category_data):
    """Test the compute_similarity function."""
    similarity_matrix = compute_similarity(sample_grade_category_data)

    # Verify that the output is a numpy array
    assert isinstance(similarity_matrix, np.ndarray)

    # Verify that the shape of the similarity matrix is (n_samples, n_samples)
    n_samples = sample_grade_category_data.shape[0]
    assert similarity_matrix.shape == (n_samples, n_samples)

    # Verify that the diagonal elements are zero (distance to itself is zero)
    assert np.all(np.diag(similarity_matrix) == 0)

    # Verify that the similarity matrix is symmetric
    assert np.allclose(similarity_matrix, similarity_matrix.T)

    # Distance between the first and second row: sqrt((1.5-1.0)^2 + (2.5-2.0)^2 + (0.6-0.5)^2) = sqrt(0.25 + 0.25 + 0.01) = sqrt(0.51)
    expected_distance_0_1 = np.sqrt(0.51)
    assert np.isclose(similarity_matrix[0, 1], expected_distance_0_1)
    assert np.isclose(similarity_matrix[1, 0], expected_distance_0_1)

    # Distance between the third and fourth row: sqrt((0.3-0.2)^2 + (0.2-0.1)^2 + (0.9-1.0)^2) = sqrt(0.01 + 0.01 + 0.01) = sqrt(0.03)
    expected_distance_2_3 = np.sqrt(0.03)
    assert np.isclose(similarity_matrix[2, 3], expected_distance_2_3)
    assert np.isclose(similarity_matrix[3, 2], expected_distance_2_3)

@pytest.fixture
def sample_df_for_similarity_matrix():
    return pd.DataFrame({
        'segment_id': ["123-456", "123-789", "456-789", "789-123"],
        'grade_category': [0.0, 0.0, 1.0, 1.0],
        'segment_length': [10, 20, 15, 25],
        'start_distance': [100, 200, 150, 250],
        'start_time': [3600, 7200, 5400, 9000],
        'start_altitude': [300, 500, 350, 550],
        'elevation_gain': [100, 200, 120, 220],
        'avg_gradient': [0.05, 0.10, 0.07, 0.12],
        'road_type': ['asphalt', 'gravel', 'asphalt', 'dirt'],
        'surface_type': ['smooth', 'rough', 'smooth', 'rough'],
        'temperature': [25, 30, 27, 32],
        'humidity': [60, 70, 65, 75],
        'wind': [5, 10, 7, 12],
        'weather_id': [100, 200, 100, 300]
    })

@patch('app.similarity_service.preprocess_data')
@patch('app.similarity_service.compute_similarity')
def test_compute_similarity_matrix(mock_compute_similarity, mock_preprocess_data, sample_df_for_similarity_matrix):
    """Test the compute_similarity_matrix function."""
    # Define expected pre-processed data for all segments (order matters)
    mock_processed_data = np.array([
        [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0],
        [ 1.0,  1.0,  1.0,  1.0,  1.0,  1.0,  1.0,  1.0,  1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0],
        [-0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0],
        [ 0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]
    ])
    mock_pipeline = None

    mock_preprocess_data.return_value = (mock_processed_data, mock_pipeline)

    # Define expected similarity matrices for each grade category
    expected_similarity_0 = np.array([[0.0, 1.41421356],
                                      [1.41421356, 0.0]])
    expected_similarity_1 = np.array([[0.0, 1.41421356],
                                      [1.41421356, 0.0]])

    # Mock the compute_similarity function's behavior based on input
    def side_effect_compute_similarity(X):
        grade_0_data = mock_processed_data[sample_df_for_similarity_matrix['grade_category'] == 0.0]
        grade_1_data = mock_processed_data[sample_df_for_similarity_matrix['grade_category'] == 1.0]
        if np.array_equal(X, grade_0_data):
            return expected_similarity_0
        elif np.array_equal(X, grade_1_data):
            return expected_similarity_1
        return np.array([[0.0]]) # Default for single segment cases

    mock_compute_similarity.side_effect = side_effect_compute_similarity

    # Call the function being tested
    similarity_data_list = compute_similarity_matrix(sample_df_for_similarity_matrix.copy())

    # Assertions f
    assert isinstance(similarity_data_list, list)
    assert len(similarity_data_list) == 2  # One pair for grade 0.0, one pair for grade 1.0

    # Create a dictionary for easier assertion
    similarity_dict = {}
    for item in similarity_data_list:
        key = tuple(sorted((item['segment_id_1'], item['segment_id_2'])))
        similarity_dict[key] = item['similarity_score']

    # Expected segment IDs based on the sample DataFrame
    segment_id_0_1 = sample_df_for_similarity_matrix[sample_df_for_similarity_matrix['grade_category'] == 0.0]['segment_id'].iloc[0]
    segment_id_0_2 = sample_df_for_similarity_matrix[sample_df_for_similarity_matrix['grade_category'] == 0.0]['segment_id'].iloc[1]
    segment_id_1_1 = sample_df_for_similarity_matrix[sample_df_for_similarity_matrix['grade_category'] == 1.0]['segment_id'].iloc[0]
    segment_id_1_2 = sample_df_for_similarity_matrix[sample_df_for_similarity_matrix['grade_category'] == 1.0]['segment_id'].iloc[1]

    assert tuple(sorted((segment_id_0_1, segment_id_0_2))) in similarity_dict
    assert np.isclose(similarity_dict[tuple(sorted((segment_id_0_1, segment_id_0_2)))], expected_similarity_0[0, 1], atol=1e-6)

    assert tuple(sorted((segment_id_1_1, segment_id_1_2))) in similarity_dict
    assert np.isclose(similarity_dict[tuple(sorted((segment_id_1_1, segment_id_1_2)))], expected_similarity_1[0, 1], atol=1e-6)

    # Verify preprocess_data was called once with the correct data
    expected_df_for_preprocess = sample_df_for_similarity_matrix[
        ['segment_length', 'start_distance', 'start_time', 'start_altitude', 'elevation_gain', 'avg_gradient',
         'road_type', 'surface_type', 'temperature', 'humidity', 'wind', 'weather_id','segment_id', 'grade_category']]
    expected_numeric_features = ['segment_length', 'start_distance', 'start_time', 'start_altitude',
                        'elevation_gain', 'avg_gradient', 'temperature', 'humidity', 'wind']
    expected_categorical_features = ['road_type', 'surface_type', 'weather_id']

    actual_args, actual_kwargs = mock_preprocess_data.call_args
    actual_df = actual_args[0] if actual_args else None

    assert actual_df is not None

    pd.testing.assert_frame_equal(actual_df, expected_df_for_preprocess)

    assert actual_args[1] == expected_numeric_features
    assert actual_args[2] == expected_categorical_features

    # Verify compute_similarity was called twice (the side_effect implicitly checks the arguments)
    assert mock_compute_similarity.call_count == 2